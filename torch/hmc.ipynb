{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Markov chain approximation (homogeneous case)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        mu_init: float,\n",
    "        sigma: float,\n",
    "        a: float,\n",
    "        z: float,\n",
    "        dt: float,\n",
    "        Nx: int,\n",
    "    ) -> None:\n",
    "        super(MCModel, self).__init__()\n",
    "        self.mu = nn.Parameter(torch.tensor([mu_init]))\n",
    "\n",
    "        self.sigma = sigma  # diffusion coeff (constant)\n",
    "        self.a, self.z = a, z  # upper boundary & starting point\n",
    "        self.Nx = Nx  # num of space steps\n",
    "        dx = a / Nx\n",
    "        self.dt, self.dx = dt, dx\n",
    "\n",
    "        self.idx_z = int(round(z / dx))  # index of starting point\n",
    "        self.init_dist = torch.zeros((1, self.Nx + 2))\n",
    "        self.init_dist[0, self.idx_z] = 1\n",
    "\n",
    "    def forward(self, T, s):\n",
    "        \"\"\"\n",
    "        compute the probability of P(X[T]=s) with a exponential scaling\n",
    "        where t is the first passage time\n",
    "        by DYNAMIC PROGRAMMING\n",
    "        s: value in [0, a]\n",
    "        \"\"\"\n",
    "        m1 = self.mu * self.dt\n",
    "        m2 = (self.mu * self.dt) ** 2 + self.sigma ** 2 * self.dt\n",
    "        p1 = (m2 / self.dx ** 2 + m1 / self.dx) / 2\n",
    "        p2 = (m2 / self.dx ** 2 - m1 / self.dx) / 2\n",
    "        assert p1 + p2 < 1, \"p+=%.5f, p0=%.5f, p-=%.5f\" % (p1, 1 - p1 - p2, p2)\n",
    "        probs = torch.cat((p2, 1 - p1 - p2, p1))\n",
    "        indices = [[0, self.Nx + 1], [self.Nx, self.Nx + 1], [self.Nx + 1, self.Nx + 1]]\n",
    "        values = torch.tensor([1, 1, 1])\n",
    "        for i in range(1, self.Nx):\n",
    "            indices.extend([[i, i - 1], [i, i], [i, i + 1]])\n",
    "            values = torch.cat((values, probs))\n",
    "        AdjMat = torch.sparse_coo_tensor(list(zip(*indices)), values, size=(self.Nx + 2, self.Nx + 2))\n",
    "        idx_T = int(round(T / self.dt))\n",
    "        idx_s = int(round(s / self.dx))\n",
    "        r = torch.tensor(0)\n",
    "        scaled_table = AdjMat.to_dense()[:, [idx_s]] / torch.exp(r)\n",
    "        for t_step in range(idx_T - 2, -1, -1):\n",
    "            b = torch.sum(torch.sparse.mm(AdjMat, scaled_table))\n",
    "            r = r + torch.log(b)\n",
    "            scaled_table = torch.sparse.mm(AdjMat, scaled_table) / b\n",
    "        return torch.sparse.mm(self.init_dist, scaled_table) * torch.exp(r)\n",
    "\n",
    "    def loss_fun(self, data):\n",
    "        \"\"\"\n",
    "        compute the average negative log likelihood\n",
    "        likelihood = product of P(X(Tk)=Ck)\n",
    "        \"\"\"\n",
    "        logprob = 0\n",
    "        for Tk, Ck in data:\n",
    "            logprob -= torch.log(self.forward(Tk, Ck))\n",
    "            if torch.isinf(logprob):\n",
    "                raise ValueError(\"Infty detected, computation is stopped.\")\n",
    "        return logprob.squeeze() / len(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data, num_epochs=100):\n",
    "    loss_history, mu_history = [], []\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        loss = model.loss_fun(data)\n",
    "        loss.backward()\n",
    "        if epoch == 1 or epoch % 1 == 0:\n",
    "            print(\"Epoch %d: Loss: %.5f; Parameters: %.5f\" % (epoch - 1, loss, model.mu))\n",
    "            loss_history.append(loss)\n",
    "            mu_history.append(model.mu)\n",
    "        mu_prev = model.mu.clone().detach().numpy()\n",
    "        optimizer.step()\n",
    "        if np.abs(mu_prev - model.mu.detach().numpy()) < 1e-4:\n",
    "            break\n",
    "    print(\"Optimization ends.\")\n",
    "    print(\"Epoch %d: Loss: %.5f; Parameters: %.5f\" % (epoch, model.loss_fun(data), model.mu))\n",
    "    loss_history.append(loss)\n",
    "    mu_history.append(model.mu)\n",
    "    return loss_history, mu_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.load('../data.npy')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddm = MCModel(mu_init=1., sigma=1, a=4, z=1.5, dt=0.01, Nx=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss: 8.78511; Parameters: 1.00000\n",
      "Epoch 1: Loss: 7.96819; Parameters: 0.68025\n",
      "Epoch 2: Loss: 7.67520; Parameters: 0.48888\n",
      "Epoch 3: Loss: 7.56954; Parameters: 0.37400\n",
      "Epoch 4: Loss: 7.53138; Parameters: 0.30495\n",
      "Epoch 5: Loss: 7.51755; Parameters: 0.26343\n",
      "Epoch 6: Loss: 7.51257; Parameters: 0.23846\n",
      "Epoch 7: Loss: 7.51077; Parameters: 0.22344\n",
      "Epoch 8: Loss: 7.51012; Parameters: 0.21441\n",
      "Epoch 9: Loss: 7.50989; Parameters: 0.20897\n",
      "Epoch 10: Loss: 7.50978; Parameters: 0.20570\n",
      "Epoch 11: Loss: 7.50976; Parameters: 0.20374\n",
      "Epoch 12: Loss: 7.50974; Parameters: 0.20256\n",
      "Epoch 13: Loss: 7.50975; Parameters: 0.20184\n",
      "Epoch 14: Loss: 7.50976; Parameters: 0.20142\n",
      "Epoch 15: Loss: 7.50976; Parameters: 0.20116\n",
      "Epoch 16: Loss: 7.50974; Parameters: 0.20100\n",
      "Optimization ends.\n",
      "Epoch 17: Loss: 7.50974; Parameters: 0.20091\n"
     ]
    }
   ],
   "source": [
    "train(ddm, data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8ec1c86f0fe716a4d325670fa96f3d850fc06e77762fd4f1d8e799712ee08f17"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
